{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist, mnist, cifar10\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "(fmnist_train, _), (fmnist_test, _) = fashion_mnist.load_data()\n",
    "\n",
    "fmnist_train = fmnist_train.astype('float32') / 255.\n",
    "fmnist_test = fmnist_test.astype('float32') / 255.\n",
    "\n",
    "fmnist_train = tf.reshape(fmnist_train, [-1, 28, 28, 1])\n",
    "fmnist_test = tf.reshape(fmnist_test, [-1, 28, 28, 1])\n",
    "\n",
    "print (fmnist_train.shape)\n",
    "print (fmnist_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "(mnist_train, _), (mnist_test, _) = mnist.load_data()\n",
    "\n",
    "mnist_train = mnist_train.astype('float32') / 255.\n",
    "mnist_test = mnist_test.astype('float32') / 255.\n",
    "\n",
    "mnist_train = tf.reshape(mnist_train, [-1, 28, 28, 1])\n",
    "mnist_test = tf.reshape(mnist_test, [-1, 28, 28, 1])\n",
    "\n",
    "print (mnist_train.shape)\n",
    "print (mnist_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "(cifar_train, _), (cifar_test, _) = cifar10.load_data()\n",
    "\n",
    "# Resize and convert to grayscale\n",
    "new_size = (28, 28)\n",
    "cifar_train_resized = np.zeros((cifar_train.shape[0], new_size[0], new_size[1], 1), dtype=np.uint8)\n",
    "cifar_test_resized = np.zeros((cifar_test.shape[0], new_size[0], new_size[1], 1), dtype=np.uint8)\n",
    "\n",
    "for i in range(cifar_train.shape[0]):\n",
    "    resized_image = cv2.resize(cifar_train[i], new_size, interpolation=cv2.INTER_LINEAR)\n",
    "    grayscale_image = cv2.cvtColor(resized_image, cv2.COLOR_RGB2GRAY)\n",
    "    cifar_train_resized[i, :, :, 0] = grayscale_image\n",
    "\n",
    "for i in range(cifar_test.shape[0]):\n",
    "    resized_image = cv2.resize(cifar_test[i], new_size, interpolation=cv2.INTER_LINEAR)\n",
    "    grayscale_image = cv2.cvtColor(resized_image, cv2.COLOR_RGB2GRAY)\n",
    "    cifar_test_resized[i, :, :, 0] = grayscale_image\n",
    "\n",
    "cifar_train = cifar_train_resized\n",
    "cifar_test = cifar_test_resized\n",
    "\n",
    "cifar_train = cifar_train.astype('float32') / 255.\n",
    "cifar_test = cifar_test.astype('float32') / 255.\n",
    "\n",
    "# x_train_resized now contains CIFAR-10 images in 28x28x1 format\n",
    "# You can use x_test_resized similarly for the test set\n",
    "print(cifar_train.shape)\n",
    "print(cifar_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ae(Model):\n",
    "  def __init__(self):\n",
    "    super(ae, self).__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Input(shape=(32, 32, 1)),\n",
    "      layers.Conv2D(16, (3, 3), activation='relu', padding='same', strides=2),\n",
    "      layers.Conv2D(8, (3, 3), activation='relu', padding='same', strides=2)])\n",
    "\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "      layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "      layers.Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "  \n",
    "autoencoder = ae()\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 9s 4ms/step - loss: 0.0074 - val_loss: 0.0024\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0011 - val_loss: 0.0011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe504fb08e0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(cifar_train, cifar_train,\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(cifar_test, cifar_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 3s 1ms/step\n",
      "(60000, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "reconstructions = autoencoder.predict(cifar_train)\n",
    "\n",
    "#print(mnist_train.shape, reconstructions.shape)\n",
    "cifar_train_loss = tf.keras.losses.mae(cifar_train, reconstructions)\n",
    "print(cifar_train_loss.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold:  0.04502763\n"
     ]
    }
   ],
   "source": [
    "threshold = np.mean(cifar_train_loss) + np.std(cifar_train_loss)\n",
    "print(\"Threshold: \", threshold)\n",
    "\n",
    "def predict(model, data, threshold):\n",
    "  reconstructions = model(data)\n",
    "  loss = tf.keras.losses.mae(reconstructions, data)\n",
    "  return tf.math.less(tf.reduce_mean(loss, axis=[1,2]), threshold)\n",
    "\n",
    "def compute_accuracy(predictions):\n",
    "    total_predictions = len(predictions)\n",
    "    correct_predictions = np.sum(predictions)\n",
    "    \n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(mnist_train, _), (mnist_test, _) = mnist.load_data()\n",
    "\n",
    "# Resize images from 28x28 to 32x32 while keeping 1 channel\n",
    "new_size = (32, 32)\n",
    "x_train_resized = np.zeros((mnist_train.shape[0], new_size[0], new_size[1], 1), dtype=np.uint8)\n",
    "x_test_resized = np.zeros((mnist_test.shape[0], new_size[0], new_size[1], 1), dtype=np.uint8)\n",
    "\n",
    "for i in range(mnist_train.shape[0]):\n",
    "    resized_image = cv2.resize(mnist_train[i], new_size, interpolation=cv2.INTER_LINEAR)\n",
    "    x_train_resized[i, :, :, 0] = resized_image\n",
    "\n",
    "for i in range(mnist_test.shape[0]):\n",
    "    resized_image = cv2.resize(mnist_test[i], new_size, interpolation=cv2.INTER_LINEAR)\n",
    "    x_test_resized[i, :, :, 0] = resized_image\n",
    "\n",
    "mnist_train = x_train_resized\n",
    "mnist_test = x_test_resized\n",
    "\n",
    "mnist_train = mnist_train.astype('float32') / 255.\n",
    "mnist_test = mnist_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(fmnist_train, _), (fmnist_test, _) = fashion_mnist.load_data()\n",
    "\n",
    "# Resize images from 28x28 to 32x32 while keeping 1 channel\n",
    "new_size = (32, 32)\n",
    "x_train_resized = np.zeros((fmnist_train.shape[0], new_size[0], new_size[1], 1), dtype=np.uint8)\n",
    "x_test_resized = np.zeros((fmnist_test.shape[0], new_size[0], new_size[1], 1), dtype=np.uint8)\n",
    "\n",
    "for i in range(fmnist_train.shape[0]):\n",
    "    resized_image = cv2.resize(fmnist_train[i], new_size, interpolation=cv2.INTER_LINEAR)\n",
    "    x_train_resized[i, :, :, 0] = resized_image\n",
    "\n",
    "for i in range(fmnist_test.shape[0]):\n",
    "    resized_image = cv2.resize(fmnist_test[i], new_size, interpolation=cv2.INTER_LINEAR)\n",
    "    x_test_resized[i, :, :, 0] = resized_image\n",
    "\n",
    "fmnist_train = x_train_resized\n",
    "fmnist_test = x_test_resized\n",
    "\n",
    "fmnist_train = fmnist_train.astype('float32') / 255.\n",
    "fmnist_test = fmnist_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "(cifar_train, _), (cifar_test, _) = cifar10.load_data()\n",
    "\n",
    "# Convert images from 32x32x3 to 32x32x1 grayscale\n",
    "x_train_gray = np.zeros((cifar_train.shape[0], cifar_train.shape[1], cifar_train.shape[2], 1), dtype=np.uint8)\n",
    "x_test_gray = np.zeros((cifar_test.shape[0], cifar_test.shape[1], cifar_test.shape[2], 1), dtype=np.uint8)\n",
    "\n",
    "for i in range(cifar_train.shape[0]):\n",
    "    grayscale_image = cv2.cvtColor(cifar_train[i], cv2.COLOR_RGB2GRAY)\n",
    "    x_train_gray[i, :, :, 0] = grayscale_image\n",
    "\n",
    "for i in range(cifar_test.shape[0]):\n",
    "    grayscale_image = cv2.cvtColor(cifar_test[i], cv2.COLOR_RGB2GRAY)\n",
    "    x_test_gray[i, :, :, 0] = grayscale_image\n",
    "\n",
    "# x_train_gray and x_test_gray now contain CIFAR-10 images in 32x32x1 grayscale format\n",
    "# You can use these grayscale datasets for further processing\n",
    "cifar_train = x_train_resized\n",
    "cifar_test = x_test_resized\n",
    "\n",
    "cifar_train = cifar_train.astype('float32') / 255.\n",
    "cifar_test = cifar_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 32, 32, 1) (10000, 32, 32, 1)\n",
      "(60000, 32, 32, 1) (10000, 32, 32, 1)\n",
      "(60000, 32, 32, 1) (10000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "print(fmnist_train.shape, fmnist_test.shape)\n",
    "print(mnist_train.shape, mnist_test.shape)\n",
    "print(cifar_train.shape, cifar_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "mnist_preds = predict(autoencoder, mnist_test, threshold)\n",
    "fmnist_preds = predict(autoencoder, fmnist_test, threshold)\n",
    "cifar_preds = predict(autoencoder, cifar_test, threshold)\n",
    "\n",
    "#print(f'Mnist Accuracy: {compute_accuracy(mnist_preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection Accuracy on Mnist: 0.0\n",
      "Detection accuracy on Fashion Mnist: 0.0031999999999999806\n",
      "Accuracy on Cifar10: 0.9968\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f'Detection Accuracy on Mnist: {1- compute_accuracy(mnist_preds)}')\n",
    "print(f'Detection accuracy on Fashion Mnist: {1- compute_accuracy(fmnist_preds)}')\n",
    "print(f'Accuracy on Cifar10: {compute_accuracy(cifar_preds)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_ssh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
